# API å…¼å®¹å±‚è®¾è®¡æ–‡æ¡£

> ç‰ˆæœ¬ï¼šv1.0
> æ—¥æœŸï¼š2025-01-31

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è®¾è®¡ä¸‰ç§ API æ ¼å¼çš„å…¼å®¹å±‚å®ç°ï¼š
- OpenAI API (`/v1/chat/completions`)
- Gemini API (`/v1beta/models/{model}:generateContent`)
- Claude API (`/v1/messages`)

æ‰€æœ‰æ ¼å¼æœ€ç»ˆéƒ½è½¬æ¢ä¸º Gemini Business API è°ƒç”¨ã€‚

---

## ğŸ”„ Gemini Business API è§„èŒƒ

### æ ¸å¿ƒç«¯ç‚¹

**åŸºç¡€ URL**ï¼š`https://biz-discoveryengine.googleapis.com/v1alpha`

#### 1. åˆ›å»º Session
```http
POST /locations/global/widgetCreateSession
Authorization: Bearer {jwt_token}
Content-Type: application/json

{
  "configId": "{team_id}",
  "additionalParams": {"token": "-"},
  "createSessionRequest": {
    "session": {"name": "", "displayName": ""}
  }
}

Response:
{
  "session": {
    "name": "projects/.../locations/global/configs/.../sessions/{session_id}"
  }
}
```

#### 2. æµå¼å¯¹è¯
```http
POST /locations/global/widgetStreamConverse
Authorization: Bearer {jwt_token}
Content-Type: application/json

{
  "configId": "{team_id}",
  "additionalParams": {"token": "-"},
  "streamConverseRequest": {
    "name": "{session_name}",
    "query": {
      "input": "ç”¨æˆ·æ¶ˆæ¯",
      "languageCode": "zh-CN"
    }
  }
}

Response: SSE Stream
data: {"message": {"text": "éƒ¨åˆ†å“åº”"}}
data: [DONE]
```

#### 3. ä¸Šä¼ æ–‡ä»¶
```http
POST /locations/global/widgetAddContextFile
Authorization: Bearer {jwt_token}
Content-Type: application/json

{
  "configId": "{team_id}",
  "additionalParams": {"token": "-"},
  "addContextFileRequest": {
    "name": "{session_name}",
    "fileName": "image.png",
    "mimeType": "image/png",
    "fileContents": "{base64_encoded_data}"
  }
}

Response:
{
  "addContextFileResponse": {
    "fileId": "xxx"
  }
}
```

---

## ğŸ¯ OpenAI API å…¼å®¹å±‚

### ç«¯ç‚¹ï¼š`POST /v1/chat/completions`

### è¯·æ±‚æ ¼å¼

```json
{
  "model": "gemini-2.5-flash",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "Hello"
    },
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "Describe this image"},
        {
          "type": "image_url",
          "image_url": {
            "url": "https://example.com/image.png"
          }
        }
      ]
    }
  ],
  "stream": true,
  "temperature": 0.7,
  "max_tokens": 2048,
  "top_p": 0.9
}
```

### æ”¯æŒçš„å­—æ®µ

| å­—æ®µ | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `model` | string | âœ… | æ¨¡å‹åç§° |
| `messages` | array | âœ… | å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ |
| `stream` | boolean | âŒ | æ˜¯å¦æµå¼è¾“å‡ºï¼ˆé»˜è®¤ falseï¼‰ |
| `temperature` | float | âŒ | æ¸©åº¦å‚æ•°ï¼ˆ0-2ï¼Œé»˜è®¤1ï¼‰ |
| `max_tokens` | integer | âŒ | æœ€å¤§è¾“å‡º token æ•° |
| `top_p` | float | âŒ | æ ¸é‡‡æ ·å‚æ•°ï¼ˆ0-1ï¼‰ |

### æ¶ˆæ¯æ ¼å¼

#### æ–‡æœ¬æ¶ˆæ¯
```json
{
  "role": "user",
  "content": "Hello"
}
```

#### å¤šæ¨¡æ€æ¶ˆæ¯
```json
{
  "role": "user",
  "content": [
    {"type": "text", "text": "Describe this image"},
    {
      "type": "image_url",
      "image_url": {
        "url": "https://example.com/image.png"
      }
    },
    {
      "type": "image_url",
      "image_url": {
        "url": "data:image/png;base64,iVBORw0KGgo..."
      }
    }
  ]
}
```

### å“åº”æ ¼å¼

#### éæµå¼å“åº”
```json
{
  "id": "chatcmpl-{uuid}",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "gemini-2.5-flash",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

#### æµå¼å“åº”ï¼ˆSSEï¼‰
```
data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1234567890,"model":"gemini-2.5-flash","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello"},"finish_reason":null}]}

data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1234567890,"model":"gemini-2.5-flash","choices":[{"index":0,"delta":{"content":"!"},"finish_reason":null}]}

data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1234567890,"model":"gemini-2.5-flash","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]
```

### è½¬æ¢é€»è¾‘ï¼šOpenAI â†’ Gemini

```python
async def openai_to_gemini(request: OpenAIChatRequest):
    """
    OpenAI æ ¼å¼è½¬æ¢ä¸º Gemini Business API è°ƒç”¨
    """
    # 1. åˆ›å»º Session
    session_name = await create_session(account)

    # 2. å¤„ç†æ¶ˆæ¯å†å²
    conversation_context = []
    uploaded_files = []

    for msg in request.messages:
        if msg.role == "system":
            # System prompt ä½œä¸ºé¦–æ¡ç”¨æˆ·æ¶ˆæ¯
            conversation_context.append({
                "role": "user",
                "text": f"[System]: {msg.content}"
            })

        elif msg.role == "user":
            # å¤„ç†æ–‡æœ¬å’Œå¤šæ¨¡æ€å†…å®¹
            if isinstance(msg.content, str):
                conversation_context.append({
                    "role": "user",
                    "text": msg.content
                })
            elif isinstance(msg.content, list):
                # å¤šæ¨¡æ€å†…å®¹ï¼šæ–‡æœ¬ + å›¾ç‰‡
                text_parts = []
                for part in msg.content:
                    if part.type == "text":
                        text_parts.append(part.text)
                    elif part.type == "image_url":
                        # ä¸Šä¼ å›¾ç‰‡åˆ° Session
                        file_id = await upload_image(
                            session_name,
                            part.image_url.url,
                            account
                        )
                        uploaded_files.append(file_id)

                conversation_context.append({
                    "role": "user",
                    "text": " ".join(text_parts)
                })

        elif msg.role == "assistant":
            conversation_context.append({
                "role": "assistant",
                "text": msg.content
            })

    # 3. æå–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
    last_user_msg = conversation_context[-1]["text"]

    # 4. æ„å»º Gemini è¯·æ±‚
    gemini_request = {
        "configId": account.team_id,
        "additionalParams": {"token": "-"},
        "streamConverseRequest": {
            "name": session_name,
            "query": {
                "input": last_user_msg,
                "languageCode": "zh-CN"
            }
        }
    }

    # 5. è°ƒç”¨ Gemini APIï¼ˆæµå¼æˆ–éæµå¼ï¼‰
    if request.stream:
        return stream_gemini_to_openai(gemini_request, request.model)
    else:
        return await call_gemini_non_stream(gemini_request, request.model)
```

### å›¾ç‰‡å¤„ç†é€»è¾‘

```python
async def upload_image(session_name: str, image_url: str, account):
    """
    ä¸Šä¼ å›¾ç‰‡åˆ° Gemini Session

    æ”¯æŒï¼š
    - HTTP/HTTPS URL
    - Data URL (base64)
    """
    if image_url.startswith("data:"):
        # Data URL: data:image/png;base64,iVBORw0KGgo...
        mime_type, base64_data = parse_data_url(image_url)
    else:
        # HTTP URL: ä¸‹è½½å›¾ç‰‡
        async with httpx.AsyncClient() as client:
            resp = await client.get(image_url)
            resp.raise_for_status()
            mime_type = resp.headers.get("content-type", "image/png")
            base64_data = base64.b64encode(resp.content).decode()

    # è°ƒç”¨ Gemini Upload API
    response = await call_gemini_upload(
        session_name=session_name,
        mime_type=mime_type,
        base64_content=base64_data,
        account=account
    )

    return response["addContextFileResponse"]["fileId"]
```

### æµå¼å“åº”è½¬æ¢

```python
async def stream_gemini_to_openai(gemini_request, model: str):
    """
    Gemini SSE æµè½¬æ¢ä¸º OpenAI SSE æµ
    """
    request_id = f"chatcmpl-{uuid.uuid4().hex[:12]}"
    created = int(time.time())

    async def event_generator():
        async for line in call_gemini_stream(gemini_request):
            if line.startswith("data: "):
                data = json.loads(line[6:])

                # Gemini æ ¼å¼ï¼š{"message": {"text": "..."}}
                if "message" in data and "text" in data["message"]:
                    chunk_text = data["message"]["text"]

                    # è½¬æ¢ä¸º OpenAI æ ¼å¼
                    openai_chunk = {
                        "id": request_id,
                        "object": "chat.completion.chunk",
                        "created": created,
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "delta": {"content": chunk_text},
                            "finish_reason": None
                        }]
                    }

                    yield f"data: {json.dumps(openai_chunk)}\n\n"

        # å‘é€ç»“æŸæ ‡è®°
        final_chunk = {
            "id": request_id,
            "object": "chat.completion.chunk",
            "created": created,
            "model": model,
            "choices": [{
                "index": 0,
                "delta": {},
                "finish_reason": "stop"
            }]
        }
        yield f"data: {json.dumps(final_chunk)}\n\n"
        yield "data: [DONE]\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )
```

---

## ğŸ§¬ Gemini API å…¼å®¹å±‚

### ç«¯ç‚¹ï¼š`POST /v1beta/models/{model}:generateContent`

### è¯·æ±‚æ ¼å¼

```json
{
  "contents": [
    {
      "role": "user",
      "parts": [
        {"text": "Hello"}
      ]
    }
  ],
  "generationConfig": {
    "temperature": 0.7,
    "maxOutputTokens": 2048,
    "topP": 0.9
  }
}
```

### å¤šæ¨¡æ€è¯·æ±‚

```json
{
  "contents": [
    {
      "role": "user",
      "parts": [
        {"text": "Describe this image"},
        {
          "inline_data": {
            "mime_type": "image/png",
            "data": "iVBORw0KGgo..."
          }
        }
      ]
    }
  ]
}
```

### å“åº”æ ¼å¼

#### éæµå¼å“åº”
```json
{
  "candidates": [
    {
      "content": {
        "parts": [
          {"text": "Hello! How can I help you?"}
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "index": 0
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 10,
    "candidatesTokenCount": 20,
    "totalTokenCount": 30
  }
}
```

#### æµå¼å“åº”
```json
data: {"candidates":[{"content":{"parts":[{"text":"Hello"}],"role":"model"},"finishReason":"NONE","index":0}]}

data: {"candidates":[{"content":{"parts":[{"text":"!"}],"role":"model"},"finishReason":"NONE","index":0}]}

data: {"candidates":[{"content":{"parts":[{"text":""}],"role":"model"},"finishReason":"STOP","index":0}]}
```

### è½¬æ¢é€»è¾‘ï¼šGemini â†’ Gemini Business

```python
async def gemini_to_gemini_business(request: GeminiGenerateRequest):
    """
    Gemini API æ ¼å¼è½¬æ¢ä¸º Gemini Business API

    æ³¨æ„ï¼šGemini API å’Œ Gemini Business API æ˜¯ä¸åŒçš„ç«¯ç‚¹
    """
    # 1. åˆ›å»º Session
    session_name = await create_session(account)

    # 2. å¤„ç† contents
    last_user_message = None
    uploaded_files = []

    for content in request.contents:
        if content.role == "user":
            for part in content.parts:
                if "text" in part:
                    last_user_message = part.text
                elif "inline_data" in part:
                    # ä¸Šä¼  base64 å›¾ç‰‡
                    file_id = await upload_image_base64(
                        session_name,
                        part.inline_data.mime_type,
                        part.inline_data.data,
                        account
                    )
                    uploaded_files.append(file_id)

    # 3. æ„å»º Gemini Business è¯·æ±‚
    gemini_business_request = {
        "configId": account.team_id,
        "additionalParams": {"token": "-"},
        "streamConverseRequest": {
            "name": session_name,
            "query": {
                "input": last_user_message,
                "languageCode": "zh-CN"
            }
        }
    }

    # 4. è°ƒç”¨å¹¶è½¬æ¢å“åº”
    if request.stream:
        return stream_gemini_business_to_gemini(gemini_business_request)
    else:
        return await call_gemini_business_to_gemini(gemini_business_request)
```

---

## ğŸ¤– Claude API å…¼å®¹å±‚

### ç«¯ç‚¹ï¼š`POST /v1/messages`

### è¯·æ±‚æ ¼å¼

```json
{
  "model": "gemini-2.5-flash",
  "messages": [
    {
      "role": "user",
      "content": "Hello"
    },
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "Describe this image"},
        {
          "type": "image",
          "source": {
            "type": "base64",
            "media_type": "image/png",
            "data": "iVBORw0KGgo..."
          }
        }
      ]
    }
  ],
  "max_tokens": 1024,
  "temperature": 0.7,
  "stream": false
}
```

### æ”¯æŒçš„å­—æ®µ

| å­—æ®µ | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `model` | string | âœ… | æ¨¡å‹åç§° |
| `messages` | array | âœ… | å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ |
| `max_tokens` | integer | âœ… | æœ€å¤§è¾“å‡º token æ•° |
| `stream` | boolean | âŒ | æ˜¯å¦æµå¼è¾“å‡ºï¼ˆé»˜è®¤ falseï¼‰ |
| `temperature` | float | âŒ | æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼‰ |

### å“åº”æ ¼å¼

#### éæµå¼å“åº”
```json
{
  "id": "msg_{uuid}",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "Hello! How can I help you?"
    }
  ],
  "model": "gemini-2.5-flash",
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 10,
    "output_tokens": 20
  }
}
```

#### æµå¼å“åº”
```
event: message_start
data: {"type":"message_start","message":{"id":"msg_xxx","type":"message","role":"assistant","content":[],"model":"gemini-2.5-flash"}}

event: content_block_start
data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}

event: content_block_delta
data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"Hello"}}

event: content_block_delta
data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"!"}}

event: content_block_stop
data: {"type":"content_block_stop","index":0}

event: message_delta
data: {"type":"message_delta","delta":{"stop_reason":"end_turn"},"usage":{"output_tokens":20}}

event: message_stop
data: {"type":"message_stop"}
```

### è½¬æ¢é€»è¾‘ï¼šClaude â†’ Gemini

```python
async def claude_to_gemini(request: ClaudeMessagesRequest):
    """
    Claude API æ ¼å¼è½¬æ¢ä¸º Gemini Business API
    """
    # è½¬æ¢é€»è¾‘ä¸ OpenAI ç±»ä¼¼ï¼Œä¸»è¦å·®å¼‚ï¼š
    # 1. Claude å›¾ç‰‡æ ¼å¼ä¸åŒï¼šsource.type = "base64"
    # 2. Claude å“åº”æ ¼å¼ä¸åŒï¼šcontent æ•°ç»„åŒ…å« text å¯¹è±¡
    # 3. Claude æµå¼äº‹ä»¶ç±»å‹ä¸åŒ

    # å¤„ç†æ¶ˆæ¯
    for msg in request.messages:
        if isinstance(msg.content, list):
            for part in msg.content:
                if part.type == "image":
                    # Claude å›¾ç‰‡æ ¼å¼
                    file_id = await upload_image_base64(
                        session_name,
                        part.source.media_type,
                        part.source.data,
                        account
                    )
```

---

## ğŸ¨ å›¾ç‰‡ç”Ÿæˆï¼ˆ-image åç¼€æ¨¡å‹ï¼‰

### è§¦å‘æ¡ä»¶
ç”¨æˆ·è¯·æ±‚çš„æ¨¡å‹åç§°åŒ…å« `-image` åç¼€ï¼ˆå¦‚ `gemini-2.5-flash-image`ï¼‰

### å¤„ç†é€»è¾‘

```python
async def handle_image_generation(request, model: str):
    """
    å¤„ç†å›¾ç‰‡ç”Ÿæˆè¯·æ±‚

    1. æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦åŒ…å« -image
    2. åœ¨ç”¨æˆ·æ¶ˆæ¯åè¿½åŠ å›¾ç‰‡ç”Ÿæˆæç¤º
    3. è§£æå“åº”ä¸­çš„å›¾ç‰‡æ–‡ä»¶
    4. è¿”å›å›¾ç‰‡ URL æˆ– Base64
    """
    # 1. ä¿®æ”¹ç”¨æˆ·æ¶ˆæ¯
    user_prompt = extract_last_user_message(request.messages)
    enhanced_prompt = f"{user_prompt}\n\nè¯·ç”Ÿæˆä¸€å¼ å›¾ç‰‡ã€‚"

    # 2. è°ƒç”¨ Gemini API
    response = await call_gemini_with_prompt(enhanced_prompt, account)

    # 3. è·å–ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶
    file_metadata = await get_session_file_metadata(
        account,
        session_name,
        filter="file_origin_type = AI_GENERATED"
    )

    # 4. ä¸‹è½½å›¾ç‰‡
    for file_id, metadata in file_metadata.items():
        image_data = await download_image(
            account,
            session_name,
            file_id
        )

        # 5. è½¬æ¢ä¸º Base64 æˆ– URL
        if output_format == "base64":
            image_base64 = base64.b64encode(image_data).decode()
            return format_image_response(
                model=model,
                content=f"data:image/png;base64,{image_base64}"
            )
        else:
            # ä¿å­˜åˆ°æœ¬åœ°/å¯¹è±¡å­˜å‚¨ï¼Œè¿”å› URL
            image_url = await save_image(image_data, file_id)
            return format_image_response(
                model=model,
                content=image_url
            )
```

### OpenAI æ ¼å¼å›¾ç‰‡å“åº”

```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "gemini-2.5-flash-image",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "data:image/png;base64,iVBORw0KGgo..."
      },
      "finish_reason": "stop"
    }
  ]
}
```

---

## ğŸ¬ è§†é¢‘ç”Ÿæˆ

### è§¦å‘æ¡ä»¶
ä½¿ç”¨ä¸“ç”¨è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚ `gemini-veo`ï¼‰

### å¤„ç†é€»è¾‘

```python
async def handle_video_generation(request, model: str):
    """
    å¤„ç†è§†é¢‘ç”Ÿæˆè¯·æ±‚

    è¿”å›æ ¼å¼ï¼šHTML embed / URL / Markdown
    """
    # 1. è°ƒç”¨ Gemini API ç”Ÿæˆè§†é¢‘
    response = await call_gemini_with_prompt(user_prompt, account)

    # 2. è·å–è§†é¢‘æ–‡ä»¶
    video_metadata = await get_session_file_metadata(
        account,
        session_name,
        filter="file_origin_type = AI_GENERATED AND mime_type LIKE 'video/%'"
    )

    # 3. ä¸‹è½½è§†é¢‘
    video_data = await download_video(account, session_name, video_file_id)

    # 4. ä¿å­˜å¹¶è¿”å› URL
    video_url = await save_video(video_data, video_file_id)

    # 5. æ ¹æ®é…ç½®æ ¼å¼è¿”å›
    if output_format == "html":
        content = f'<video src="{video_url}" controls></video>'
    elif output_format == "markdown":
        content = f"![Generated Video]({video_url})"
    else:
        content = video_url

    return format_video_response(model=model, content=content)
```

---

## ğŸ›¡ï¸ é”™è¯¯å¤„ç†

### é”™è¯¯ç æ˜ å°„

| Gemini Business é”™è¯¯ | HTTP çŠ¶æ€ç  | è¯´æ˜ | å¤„ç†ç­–ç•¥ |
|---------------------|-----------|------|---------|
| 401 Unauthorized | 401 | Token è¿‡æœŸ | åˆ·æ–° Token åé‡è¯• |
| 403 Forbidden | 403 | æƒé™ä¸è¶³ | æ ‡è®°è´¦å·å†·å´ï¼ˆ2å°æ—¶ï¼‰ |
| 429 Too Many Requests | 429 | é™æµ | æ ‡è®°è´¦å·å†·å´ï¼ˆ4å°æ—¶ï¼‰ |
| 400 Bad Request | 400 | å‚æ•°é”™è¯¯ | ç›´æ¥è¿”å›ç»™å®¢æˆ·ç«¯ |
| 500 Internal Error | 500 | æœåŠ¡å™¨é”™è¯¯ | é‡è¯•ï¼ˆæœ€å¤š3æ¬¡ï¼‰ |

### é”™è¯¯å“åº”æ ¼å¼

#### OpenAI æ ¼å¼
```json
{
  "error": {
    "message": "Token expired, please retry",
    "type": "invalid_request_error",
    "code": "token_expired"
  }
}
```

#### Gemini æ ¼å¼
```json
{
  "error": {
    "code": 401,
    "message": "Token expired",
    "status": "UNAUTHENTICATED"
  }
}
```

#### Claude æ ¼å¼
```json
{
  "type": "error",
  "error": {
    "type": "authentication_error",
    "message": "Token expired"
  }
}
```

---

## ğŸ“Š è¯·æ±‚æµç¨‹å›¾

```
å®¢æˆ·ç«¯è¯·æ±‚ â†’ è·¯ç”±åˆ†å‘ â†’ æ ¼å¼éªŒè¯
    â†“
è¯†åˆ« API æ ¼å¼ (OpenAI/Gemini/Claude)
    â†“
æå–æ¶ˆæ¯å’Œå¤šæ¨¡æ€å†…å®¹
    â†“
ä»è´¦å·æ± è·å–å¯ç”¨è´¦å· â†’ Token Manager è·å– JWT
    â†“
åˆ›å»º Gemini Session
    â†“
ä¸Šä¼ å›¾ç‰‡/è§†é¢‘ï¼ˆå¦‚æœ‰ï¼‰
    â†“
è°ƒç”¨ Gemini Business API
    â†“
æµå¼/éæµå¼å“åº”è½¬æ¢
    â†“
è¿”å›å¯¹åº”æ ¼å¼çš„å“åº”ç»™å®¢æˆ·ç«¯
```

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶æ¥å£è®¾è®¡

### 1. æ ¼å¼è½¬æ¢å™¨æ¥å£

```python
class APIConverter(ABC):
    """API æ ¼å¼è½¬æ¢å™¨åŸºç±»"""

    @abstractmethod
    async def convert_request(self, request) -> GeminiBusinessRequest:
        """å°†ç‰¹å®šæ ¼å¼è¯·æ±‚è½¬æ¢ä¸º Gemini Business è¯·æ±‚"""
        pass

    @abstractmethod
    async def convert_response(self, gemini_response) -> dict:
        """å°† Gemini Business å“åº”è½¬æ¢ä¸ºç‰¹å®šæ ¼å¼"""
        pass

    @abstractmethod
    async def stream_response(self, gemini_stream) -> AsyncGenerator:
        """å°† Gemini Business æµå¼å“åº”è½¬æ¢ä¸ºç‰¹å®šæ ¼å¼"""
        pass
```

### 2. å¤šæ¨¡æ€å¤„ç†å™¨

```python
class MultimodalHandler:
    """å¤šæ¨¡æ€å†…å®¹å¤„ç†å™¨"""

    async def process_images(
        self,
        session_name: str,
        images: List[ImageInput],
        account: Account
    ) -> List[str]:
        """å¤„ç†å›¾ç‰‡åˆ—è¡¨ï¼Œè¿”å› file_id åˆ—è¡¨"""
        pass

    async def download_generated_images(
        self,
        session_name: str,
        account: Account
    ) -> List[bytes]:
        """ä¸‹è½½ AI ç”Ÿæˆçš„å›¾ç‰‡"""
        pass

    async def download_generated_videos(
        self,
        session_name: str,
        account: Account
    ) -> List[bytes]:
        """ä¸‹è½½ AI ç”Ÿæˆçš„è§†é¢‘"""
        pass
```

### 3. å“åº”æµè½¬æ¢å™¨

```python
class StreamConverter:
    """æµå¼å“åº”è½¬æ¢å™¨"""

    @staticmethod
    async def gemini_to_openai_stream(
        gemini_stream: AsyncGenerator,
        model: str
    ) -> AsyncGenerator:
        """Gemini SSE â†’ OpenAI SSE"""
        pass

    @staticmethod
    async def gemini_to_claude_stream(
        gemini_stream: AsyncGenerator,
        model: str
    ) -> AsyncGenerator:
        """Gemini SSE â†’ Claude SSE"""
        pass
```

---

## âœ… å®ç°ä¼˜å…ˆçº§

### Phase 1ï¼šåŸºç¡€åŠŸèƒ½
1. âœ… OpenAI `/v1/chat/completions` æ–‡æœ¬å¯¹è¯ï¼ˆéæµå¼ï¼‰
2. âœ… Token åˆ·æ–°å’Œè´¦å·æ± ç®¡ç†
3. âœ… é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### Phase 2ï¼šæµå¼å“åº”
1. âœ… OpenAI æµå¼å“åº”
2. âœ… Gemini æµå¼å“åº”
3. âœ… Claude æµå¼å“åº”

### Phase 3ï¼šå¤šæ¨¡æ€
1. âœ… å›¾ç‰‡è¾“å…¥ï¼ˆURL å’Œ Base64ï¼‰
2. âœ… å›¾ç‰‡ç”Ÿæˆï¼ˆ-image æ¨¡å‹ï¼‰
3. âœ… è§†é¢‘ç”Ÿæˆ

### Phase 4ï¼šå®Œæ•´ API æ”¯æŒ
1. âœ… Gemini API å®Œæ•´æ”¯æŒ
2. âœ… Claude API å®Œæ•´æ”¯æŒ
3. âœ… é…ç½®çƒ­é‡è½½

---

**æ–‡æ¡£ç‰ˆæœ¬å†å²ï¼š**
- v1.0 (2025-01-31): åˆå§‹ç‰ˆæœ¬ï¼Œå®Œæˆä¸‰ç§ API æ ¼å¼çš„è¯¦ç»†è®¾è®¡
